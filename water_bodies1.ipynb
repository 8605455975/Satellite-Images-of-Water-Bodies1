{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2GZdl3Kq1Oq"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images_dir = '/content/drive/MyDrive/Satellite Images of Water Bodies/Water Bodies Dataset/Images'\n",
        "masks_dir = '/content/drive/MyDrive/Satellite Images of Water Bodies/Water Bodies Dataset/Masks'\n",
        "\n",
        "dirname, _, filenames = next(os.walk(images_dir))"
      ],
      "metadata": {
        "id": "mIeDGB0DsAMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files=[]\n",
        "paths = []\n",
        "for dirname, _, filenames in os.walk(images_dir):\n",
        "    for filename in filenames:\n",
        "        path = os.path.join(dirname, filename)    \n",
        "        paths.append(path)\n",
        "        files.append(filename)"
      ],
      "metadata": {
        "id": "zTTQ_k3AxU_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mfiles=[]\n",
        "mpaths = []\n",
        "for dirname, _, filenames in os.walk(masks_dir):\n",
        "    for filename in filenames:\n",
        "        path = os.path.join(dirname, filename)    \n",
        "        mpaths.append(path)\n",
        "        mfiles.append(filename)"
      ],
      "metadata": {
        "id": "7eoF55qlxeZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "path0='/content/drive/MyDrive/Satellite Images of Water Bodies/Water Bodies Dataset/Images/water_body_10.jpg'\n",
        "img0=cv2.imread(path0,cv2.IMREAD_GRAYSCALE)\n",
        "shape0=img0.shape\n",
        "print(shape0)\n",
        "plt.imshow(img0)\n",
        "plt.show()\n",
        "\n",
        "path1='/content/drive/MyDrive/Satellite Images of Water Bodies/Water Bodies Dataset/Masks/water_body_10.jpg'\n",
        "img1=cv2.imread(path1,cv2.IMREAD_GRAYSCALE)\n",
        "shape1=img1.shape\n",
        "print(shape1)\n",
        "plt.imshow(img1)\n",
        "plt.show()\n",
        "(2009, 2007)"
      ],
      "metadata": {
        "id": "1DzjsD_UxqxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n=len(df0)\n",
        "df=df0.iloc[0:(n//10)*3]\n",
        "test_df=df0.iloc[(n//10)*3:(n//10)*4]"
      ],
      "metadata": {
        "id": "fXe4p2-t3kh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = [256,256]\n",
        "\n",
        "def data_augmentation(car_img, mask_img):\n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        car_img = tf.image.flip_left_right(car_img)\n",
        "        mask_img = tf.image.flip_left_right(mask_img)\n",
        "\n",
        "    return car_img, mask_img\n",
        "\n",
        "def preprocessing(car_path, mask_path):\n",
        "    car_img = tf.io.read_file(car_path) \n",
        "    car_img = tf.image.decode_jpeg(car_img, channels=3)\n",
        "    car_img = tf.image.resize(car_img, img_size)\n",
        "    car_img = tf.cast(car_img, tf.float32) / 255.0\n",
        "    \n",
        "    mask_img = tf.io.read_file(mask_path)\n",
        "    mask_img = tf.image.decode_jpeg(mask_img, channels=3)\n",
        "    mask_img = tf.image.resize(mask_img, img_size)\n",
        "    mask_img = mask_img[:,:,:1]    \n",
        "    mask_img = tf.math.sign(mask_img)\n",
        "    \n",
        "    return car_img, mask_img\n",
        "\n",
        "def create_dataset(df, train = False):\n",
        "    if not train:\n",
        "        ds = tf.data.Dataset.from_tensor_slices((df[\"path\"].values, df[\"mpath\"].values))\n",
        "        ds = ds.map(preprocessing, tf.data.AUTOTUNE)\n",
        "    else:\n",
        "        ds = tf.data.Dataset.from_tensor_slices((df[\"path\"].values, df[\"mpath\"].values))\n",
        "        ds = ds.map(preprocessing, tf.data.AUTOTUNE)\n",
        "        ds = ds.map(data_augmentation, tf.data.AUTOTUNE)\n",
        "\n",
        "    return ds"
      ],
      "metadata": {
        "id": "i9Hp8pUp3si0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nf07paCw30J4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}